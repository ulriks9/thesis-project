{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import wave\n",
    "import pylab\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as nn\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras, einsum\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from functools import partial\n",
    "from inspect import isfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress tf error messages:\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Configure GPU memory settings\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BETA_TIMESTEPS = 1000\n",
    "UPSAMPLE_KERNEL_SIZE = 4\n",
    "DOWNSAMPLE_KERNEL_SIZE = 4\n",
    "WAVE_PATH = \"data/musicnet/musicnet/musicnet/train_data/\"\n",
    "SPECTRO_PATH = \"data/musicnet/spectrograms/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "img_channels = 1\n",
    "\n",
    "def preprocess(x, _):\n",
    "    return tf.image.resize(tf.cast(x, tf.float32) / 127.5 - 1, img_size)\n",
    "\n",
    "def get_mnist():\n",
    "    train_ds = tfds.load('mnist', as_supervised=True, split='train')\n",
    "\n",
    "    # Normalize and shuffle:\n",
    "    train_ds = train_ds.map(preprocess, tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.shuffle(5000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return tfds.as_numpy(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get information about a wave file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wav_info(file):\n",
    "    wav = wave.open(file, 'rb')\n",
    "    frames = wav.readframes(-1)\n",
    "    info = pylab.frombuffer(frames, 'int16')\n",
    "    frame_rate = wav.getframerate()\n",
    "    wav.close()\n",
    "    \n",
    "    return info, frame_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset with spectrograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SPECTRO_PATH):\n",
    "    os.mkdir(SPECTRO_PATH)\n",
    "    \n",
    "start = time.time()    \n",
    "print(\"INFO: Converting wav to spectrograms.\")\n",
    "\n",
    "for file in os.listdir(WAVE_PATH):\n",
    "    info, frame_rate = wav_info(os.path.join(WAVE_PATH, file))\n",
    "    pylab.specgram(info, Fs=frame_rate)\n",
    "    pylab.savefig(f\"{file}.png\")\n",
    "    pylab.close()\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"INFO: Spectrograms have been successfully created in {str(end - start)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Show an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_mnist()\n",
    "# for example in data:\n",
    "#     first = example\n",
    "#     break\n",
    "\n",
    "# img = first[0]\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Forward Noise Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear noise schedule:\n",
    "beta = np.linspace(0.0001, 0.02, BETA_TIMESTEPS)\n",
    "\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[:-1]), axis=0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "\n",
    "# Should it not be 1 - alpha_bar * Identity?\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1 - alpha_bar)\n",
    "\n",
    "# Set a key for the Numpy random seed:\n",
    "def set_key(key):\n",
    "    np.random.seed(key)\n",
    "\n",
    "def forward_noise(key, x_0, t):\n",
    "    set_key(key)\n",
    "\n",
    "    noise = np.random.normal(size=x_0.shape)\n",
    "    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    noisy_image = reshaped_sqrt_alpha_bar_t * x_0 + reshaped_one_minus_sqrt_alpha_bar_t * noise\n",
    "    \n",
    "    return noisy_image, noise\n",
    "\n",
    "# This function will be used to create sample timestamps between 0 & T\n",
    "def generate_timestamp(key, num):\n",
    "    set_key(key)\n",
    "    return tf.random.uniform(shape=[num], minval=0, maxval=BETA_TIMESTEPS, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test forward process:\n",
    "This also higlights the issue with a linear schedule. Already at timestep 250, the image is almost completely noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = next(iter(data))[0]\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 30))\n",
    "\n",
    "# for index, i in enumerate([1, 50, 100, 199]):\n",
    "#     noisy_img, _ = forward_noise(0, np.expand_dims(sample, 0), np.array([i,]))\n",
    "#     plt.subplot(1, 4, index + 1)\n",
    "#     plt.imshow(np.squeeze(np.squeeze(noisy_img, -1), 0), cmap='gray')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions:\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert time to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(Layer):\n",
    "    def __init__(self, dim, max_positions=10000):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.max_positions = max_positions\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        half_dim = self.dim // 2\n",
    "\n",
    "        emb = math.log(self.max_positions) / (half_dim - 1)\n",
    "        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return tf.identity(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        return self.fn(x, training=training) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(dim):\n",
    "    return nn.Conv2DTranspose(filters=dim, kernel_size=UPSAMPLE_KERNEL_SIZE, strides=2, padding='SAME')\n",
    "\n",
    "def downsample(dim):\n",
    "    return nn.Conv2D(filters=dim, kernel_size=DOWNSAMPLE_KERNEL_SIZE, strides=2, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(Layer):\n",
    "    def __init__(self, dim, eps=1e-5, **kwargs):\n",
    "        super(LayerNorm, self).__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.g = tf.Variable(tf.ones([1,1,1,dim]))\n",
    "        self.b = tf.Variable(tf.zeros([1,1,1,dim]))\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        var = tf.math.reduce_variance(x, axis=-1, keepdims=True)\n",
    "        mean = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "\n",
    "        x = (x - mean) / tf.sqrt((var + self.eps)) * self.g + self.b\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiLu(Layer):\n",
    "    def __init__(self):\n",
    "        super(SiLu, self).__init__()\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        return x * tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x, approximate=False):\n",
    "    if approximate:\n",
    "        coeff = tf.cast(0.044715, x.dtype)\n",
    "\n",
    "        return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "    else:\n",
    "        return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "class GELU(Layer):\n",
    "    def __init__(self, approximate=False):\n",
    "        super(GELU, self).__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return gelu(x, self.approximate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(Layer):\n",
    "    def __init__(self, dim, groups=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.proj = nn.Conv2D(dim, kernel_size=3, strides=1, padding='SAME')\n",
    "        self.norm = tfa.layers.GroupNormalization(groups, epsilon=1e-05)\n",
    "        self.act = SiLu()\n",
    "\n",
    "    def call(self, x, gamma_beta=None, training=True):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x, training=training)\n",
    "\n",
    "        if exists(gamma_beta):\n",
    "            gamma, beta = gamma_beta\n",
    "            x = x * (gamma + 1) + beta\n",
    "\n",
    "        x = self.act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(Layer):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim=None, groups=8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.mlp = Sequential([\n",
    "            SiLu(),\n",
    "            nn.Dense(units=dim_out * 2)\n",
    "        ]) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2D(filters=dim_out, kernel_size=1, strides=1) if dim != dim_out else Identity()\n",
    "\n",
    "    def call(self, x, time_emb=None, training=True):\n",
    "        gamma_beta = None\n",
    "\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b 1 1 c')\n",
    "            gamma_beta = tf.split(time_emb, num_or_size_splits=2, axis=-1)\n",
    "\n",
    "        h = self.block1(x, gamma_beta=gamma_beta, training=training)\n",
    "        h = self.block2(h, training=training)\n",
    "\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAttention(Layer):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Conv2D(filters=self.hidden_dim * 3, kernel_size=1, strides=1, use_bias=False)\n",
    "\n",
    "        self.to_out = Sequential([\n",
    "            nn.Conv2D(filters=dim, kernel_size=1, strides=1),\n",
    "            LayerNorm(dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "\n",
    "        q = tf.nn.softmax(q, axis=-2)\n",
    "        k = tf.nn.softmax(k, axis=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b x y (h c)', h=self.heads, x=h, y=w)\n",
    "        out = self.to_out(out, training=training)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2D(filters=self.hidden_dim * 3, kernel_size=1, strides=1, use_bias=False)\n",
    "        self.to_out = nn.Conv2D(filters=dim, kernel_size=1, strides=1)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        sim_max = tf.stop_gradient(tf.expand_dims(tf.argmax(sim, axis=-1), axis=-1))\n",
    "        sim_max = tf.cast(sim_max, tf.float32)\n",
    "        sim = sim - sim_max\n",
    "        attn = tf.nn.softmax(sim, axis=-1)\n",
    "\n",
    "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h (x y) d -> b x y (h d)', x = h, y = w)\n",
    "        out = self.to_out(out, training=training)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(Model):\n",
    "    def __init__(self,\n",
    "                 dim=64,\n",
    "                 init_dim=None,\n",
    "                 out_dim=None,\n",
    "                 dim_mults=(1, 2, 4, 8),\n",
    "                 channels=3,\n",
    "                 resnet_block_groups=8,\n",
    "                 learned_variance=False,\n",
    "                 sinusoidal_cond_mlp=True\n",
    "                 ):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "        \n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2D(filters=init_dim, kernel_size=7, strides=1, padding='SAME')\n",
    "        \n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        \n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "        \n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "        self.sinusoidal_cond_mlp = sinusoidal_cond_mlp\n",
    "        \n",
    "        self.time_mlp = Sequential([\n",
    "            SinusoidalPosEmb(dim),\n",
    "            nn.Dense(units=time_dim),\n",
    "            GELU(),\n",
    "            nn.Dense(units=time_dim)\n",
    "        ], name=\"time embeddings\")\n",
    "        \n",
    "        # layers\n",
    "        self.downs = []\n",
    "        self.ups = []\n",
    "        num_resolutions = len(in_out)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append([\n",
    "                block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                downsample(dim_out) if not is_last else Identity()\n",
    "            ])\n",
    "  \n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append([\n",
    "                block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                upsample(dim_in) if not is_last else Identity()\n",
    "            ])\n",
    "        \n",
    "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "        \n",
    "        self.final_conv = Sequential([\n",
    "            block_klass(dim * 2, dim),\n",
    "            nn.Conv2D(filters=self.out_dim, kernel_size=1, strides=1)\n",
    "        ], name=\"output\")\n",
    "        \n",
    "    def call(self, x, time=None, training=True, **kwargs):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time)\n",
    "        \n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = tf.concat([x, h.pop()], axis=-1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = tf.concat([x, h.pop()], axis=-1)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(channels=1)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(unet=unet)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, \"./checkpoints\", max_to_keep=2)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    start_interation = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "test_images = np.ones([1, 32, 32, 1])\n",
    "test_timestamps = generate_timestamp(0, 1)\n",
    "\n",
    "k = unet(test_images, test_timestamps)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(real, generated):\n",
    "    loss = tf.math.reduce_mean((real - generated) ** 2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 0\n",
    "\n",
    "def train_step(batch):\n",
    "    rng, tsrng = np.random.randint(0, 100000, size=(2,))\n",
    "    timestep_values = generate_timestamp(tsrng, batch.shape[0])\n",
    "\n",
    "    noised_image, noise = forward_noise(rng, batch, timestep_values)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = unet(noised_image, timestep_values)\n",
    "        loss_value = loss_fn(noise, prediction)\n",
    "    \n",
    "    gradients = tape.gradient(loss_value, unet.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, unet.trainable_variables))\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    bar = tf.keras.utils.Progbar(len(data) - 1)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i, batch in enumerate(iter(data)):\n",
    "        loss = train_step(batch)\n",
    "        losses.append(loss)\n",
    "        bar.update(i, values=[(\"loss\", loss)])\n",
    "\n",
    "    avg = np.mean(losses)\n",
    "    print(f\"Average loss for epoch {e}/{epochs}: {avg}\")\n",
    "    ckpt_manager.save(checkpoint_number=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a GIF using logged images\n",
    "def save_gif(img_list, path=\"\", interval=200):\n",
    "    # Transform images from [-1,1] to [0, 255]\n",
    "    imgs = []\n",
    "    for im in img_list:\n",
    "        im = np.array(im)\n",
    "        im = (im + 1) * 127.5\n",
    "        im = np.clip(im, 0, 255).astype(np.int32)\n",
    "        im = Image.fromarray(im)\n",
    "        imgs.append(im)\n",
    "    \n",
    "    imgs = iter(imgs)\n",
    "\n",
    "    # Extract first image from iterator\n",
    "    img = next(imgs)\n",
    "\n",
    "    # Append the other images and save as GIF\n",
    "    img.save(fp=path, format='GIF', append_images=imgs,\n",
    "             save_all=True, duration=interval, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm(x_t, pred_noise, t):\n",
    "    alpha_t = np.take(alpha, t)\n",
    "    alpha_t_bar = np.take(alpha_bar, t)\n",
    "\n",
    "    eps_coef = (1 - alpha_t) / (1 - alpha_t_bar) ** .5\n",
    "    mean = (1 / (alpha_t ** .5)) * (x_t - eps_coef * pred_noise)\n",
    "\n",
    "    var = np.take(beta, t)\n",
    "    z = np.random.normal(size=x_t.shape)\n",
    "\n",
    "    return mean + (var ** .5) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_noise = tf.random.normal((1,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = copy.deepcopy(input_noise)\n",
    "img_list = []\n",
    "img_list.append(np.squeeze(np.squeeze(x, 0),-1))\n",
    "\n",
    "for i in tqdm(range(BETA_TIMESTEPS-1)):\n",
    "    t = np.expand_dims(np.array(BETA_TIMESTEPS-i-1, np.int32), 0)\n",
    "    pred_noise = unet(x, t)\n",
    "    x = ddpm(x, pred_noise, t)\n",
    "    img_list.append(np.squeeze(np.squeeze(x, 0),-1))\n",
    "\n",
    "    if i % 100==0:\n",
    "        plt.imshow(np.array(np.clip((x[0] + 1) * 127.5, 0, 255), np.uint8), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "save_gif(img_list + ([img_list[-1]] * 100), \"ddpm.gif\", interval=20)\n",
    "\n",
    "plt.imshow(np.array(np.clip((x[0] + 1) * 127.5, 0, 255), np.uint8))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e994aec9224f641ea631badc3b8b36b698e381bd14530941acad14114f6512c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
